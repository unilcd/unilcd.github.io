<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="CaT: Coaching a Teachable Student">
  <meta name="keywords" content="Coaching a Teachable Student, CaT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CaT: Coaching a Teachable Student</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="./favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <meta property="og:site_name" content="CaT: Coaching a Teachable Student" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="CaT: Coaching a Teachable Student" />
  <meta property="og:description" content="Zhang, et al. CaT: Coaching a Teachable Student." />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="CaT: Coaching a Teachable Student" />
  <meta name="twitter:description" content="Zhang, et al. CaT: Coaching a Teachable Student." />

  <script src="https://www.youtube.com/iframe_api"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CaT: Coaching a Teachable Student</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://jimuyangz.github.io/">Jimuyang Zhang</a>&emsp;
                <a href="https://tzmhuang.github.io/">Zanming Huang</a>&emsp;
                <a href="https://eshed1.github.io/">Eshed Ohn-Bar</a>&emsp;
                <br />Boston University
                <span class="brmod"></span>CVPR 2023 (Highlight)</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
<!--                 <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./resources/CaT.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2306.10014" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="#method_video" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/h2xlab/CaT" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Slides Link. -->
                <!-- <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                  </span>
                  <span>Slides</span>
                  </a>
              </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered">
      <div class="column is-6">
        <img src="./resources/example1.gif" />
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </div>
</section>
 -->


  <section class="section">
    <div class="container">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-two-thirds">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We propose a novel knowledge distillation framework for
              effectively teaching a sensorimotor student agent to drive
              from the supervision of a privileged teacher agent. Current
              distillation for sensorimotor agents methods tend to result
              in suboptimal learned driving behavior by the student,
              which we hypothesize is due to inherent differences between
              the input, modeling capacity, and optimization processes of
              the two agents. We develop a novel distillation scheme that
              can address these limitations and close the gap between the
              sensorimotor agent and its privileged teacher. Our key insight
              is to design a student which learns to align their input
              features with the teacher’s privileged Bird’s Eye View (BEV)
              space. The student then can benefit from direct supervision
              by the teacher over the internal representation learning. To
              scaffold the difficult sensorimotor learning task, the student
              model is optimized via a student-paced coaching mechanism with 
              various auxiliary supervision. We further propose
              a high-capacity imitation learned privileged agent that surpasses
              prior privileged agents in CARLA and ensures the
              student learns safe driving behavior. Our proposed sensorimotor
              agent results in a robust image-based behavior
              cloning agent in CARLA, improving over current models
              by over 20.6% in driving score without requiring LiDAR,
              historical observations, ensemble of models, on-policy data
              aggregation or reinforcement learning.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!-- Paper video. -->
    <br />
    <br />
    <div id="method_video" class="columns is-centered has-text-centered">
      <div class="column is-half">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- <video controls>
            <source src="./resources/CaT_Video.mp4" type="video/mp4">
          </video> -->
          <iframe src="https://www.youtube.com/embed/5tmkDHfgqvU"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

  </section>


  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Motivation</h2>
          <div class="content has-text-justified">
            <p>
              To ease the challenging sensorimotor agent training task, recent approaches decompose the task into
              stages, by first training a privileged network with complete knowledge of the world and distilling its
              knowledge into a less capable student network. However, current distillation methods for sensorimotor
              agents result in <b>suboptimal driving behavior</b> due to <b>inherent differences between the inputs,
                modeling
                capacity</b>, and <b>optimization processes of the two agents.</b> </p>
            </p>
            <div class="column">
              <img src="./resources/lbc_diagram.png" />
            </div>

            <div class="content has-text-centered">
              <i>Chen, et al. CoRL 2020</i>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            We develop a novel deep distillation scheme that can address these
            limitations and close the gap between the sensorimotor agent and its
            privileged teacher. We achieve this by

            <ol>
              <li><b>Effective Teacher</b>: We propose to incorporate explicit safety-aware cues
                into the BEV space that facilitate a surprisingly effective teacher agent
                design. We demonstrate our learned agent to match expert- level decisionmaking.</li>

              <li><b>Teachable Student via Alignment</b>: An IPM-based transformer alignment
                module can facilitate direct distillation of most of the teacher’s features and
                better guide the student learning process.</li>

              <li><b>Student-paced Coaching</b>: A coaching mechanism for managing difficult
                samples can scaffold knowledge and lead to improved model optimization
                by better considering the ability of the student.</li>
            </ol>
          </div>
        </div>
      </div>



      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Effective Teacher</h2>
          <div class="content has-text-justified">
            Given the low performance of prior privileged agents, the teacher could benefit from more <b>explicit
            safety-driven cues in the BEV</b>. We propose to add two types of channels of predicted agents’ future and
            entity attention. We first utilize a kinematics bicycle model to predict future trajectories of dynamic
            objects, which enables us to iteratively predict and represent short-term future position, orientation, and
            speed of agent. Then, we encode an explicit attention channel for highlighting potential future infractions.
            Our boosted teacher agent even improves over the rule-based expert.

          </div>
          <div class="column">
            <img src="./resources/bev_figure.png" width="80%" />
          </div>
        </div>
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Teachable student via Alignment</h2>
          <div class="content has-text-justified">
            Due to the difference between inputs and modeling capacities, it can be difficult to align the image-based
            student features and output with the BEV-based privileged teacher. Therefore, we proposed an <b>IPM-based
              transformer alignment module</b> that can facilitate direct distillation of most of the teacher’s features
            and better
            guide the student learning process.
          </div>
          <div class="column">
            <img src="./resources/figure1_crop.png" width="80%" />
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Student-paced Coaching</h2>
          <div class="content has-text-justified">
            To better consider the learning ability of the student, we gradually coach the student with a student-paced
            coaching mechanism. Specifically, we interpolate between teacher features and student features on samples
            that the student performed poorly (i.e. higher loss). This effectively adjusts the learning rate in a
            sample-selective manner, which aims to stabilize training by reducing the difficulty when the student is
            unable to perform the optimal action.
          </div>

          <div class="column">
            <img src="./resources/student_pace.png" width="50%" />
          </div>

        </div>
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Model Architecture of CaT</h2>
          <div class="content has-text-justified">
            <p>
              Our proposed CaT framework
              enables highly effective knowledge transfer between a privileged
              teacher and a sensorimotor (i.e., image-based) student.

              Specifically, we first sample queries using a spatial parameterization of the BEV space and process them
              with a self-attention module. Then, a deformable cross-attention module is applied to populate the
              student’s BEV features.

              The residual blocks following the alignment module can consequently facilitate knowledge transfer via
              direct distillation of most of the teacher’s features.


              Our optimization objective for guiding the distillation process is a weighted sum over both distillation
              and auxiliary tasks, including output distillation loss, feature distillation loss, segmentation loss and
              command prediction loss.
            </p>
            <div class="column">
              <img src="./resources/method.png" />
            </div>

          </div>
        </div>
      </div>


    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Result</h2>
          <div class="content has-text-justified">
            We present our closed-loop evaluation results on the Longest-6 Benchmark in CARLA. As illustrated in the
            table below, CaT is able to achieve state of the art performance among all prior agents, including lidar
            based
            approaches. Moreover, we note that our privileged BEV agent learned by imitation with history and desired
            path, agent forecast, and entity attention even outperforms the rule-based expert.
          </div>
          <div class="column">
            <img src="./resources/results.png" width="80%" />
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Qualitative Examples</h2>
            <video controls>
            <source src="./resources/CaT_Video.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </section>


  <section class="section id=" BibTeX"">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">BibTeX</h2>
          <div class="content has-text-justified">
            <pre><code>@inproceedings{zhang2023coaching,
        title={Coaching a Teachable Student},
        author={Zhang, Jimuyang and Huang, Zanming and Ohn-Bar, Eshed},
        booktitle={CVPR},
        year={2023}
}</code></pre>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section id=" BibTeX"">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Acknowledgments</h2>
          <div class="content has-text-centered">
            We thank the Red Hat Collaboratory
            for supporting this research.

          </div>
        </div>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a href="./resources/CaT.pdf" class="large-font bottom_buttons">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a href="TODO" class="large-font bottom_buttons">
          <i class="fab fa-github"></i>
        </a>
        <br />
        <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">D-NeRF</span></a> and <a
            href="https://worldsheet.github.io/"><span>Worldsheet</span> and <a
              href="https://zlai0.github.io/VideoAutoencoder/"><span>Video Autoencoder</span>.</p>
      </div>
    </div>
  </footer>

</body>

</html>
