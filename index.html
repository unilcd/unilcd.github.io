<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Unified Local-Cloud Decision-Making via Reinforcement Learning">
  <meta name="keywords" content="Local-Cloud, Residual RL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="./favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <meta property="og:site_name" content="UniLCD: Unified Local-Cloud Decision-Making with Residual Reinforcement Learning" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning" />
  <meta property="og:description" content="Sengupta, et al. UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning." />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning" />
  <meta name="twitter:description" content="Sengupta, et al. UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning." />

  <script src="https://www.youtube.com/iframe_api"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">UniLCD: Unified Local-Cloud Decision-Making via Reinforcement Learning</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://diasengupta.github.io/">Kathakoli Sengupta</a>&emsp;
                <a href="https://www.linkedin.com/in/sgzk/">Zhongkai Shagguan</a>&emsp;
                <a href="https://www.linkedin.com/in/sandeshbharadwaj97/">Sandesh Bharadwaj</a>&emsp;
                <a href="https://research.redhat.com/blog/project_member/sanjay-arora/">Sanjay Arora</a>&dagger;&emsp;
                <a href="https://eshed1.github.io/">Eshed Ohn-Bar</a>&emsp;
                <a href="https://cpslab.bu.edu/ ">Renato Mancuso</a>&emsp;
                <br />Boston University, RedHat&dagger;
                <span class="brmod"></span>ECCV 2024</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/10oI-lWYgri49F047VdHN2Y2Xoc6zqc34/view?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-alt"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="#method_video" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/DIASENGUPTA/UniLCD" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Data Link. -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1KOB7TMVxUFEBGvveIi5JuMBjFvs_kqxk?usp=share_link" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <!-- Data Link. -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1KYA01bB1ZRck-55Y9jUsxJQWa0AWiRLy/view?usp=share_link" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-alt"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>
                
                <!-- Slides Link. -->
                <!-- <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                  </span>
                  <span>Slides</span>
                  </a>
              </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered">
      <div class="column is-6">
        <img src="./resources/example1.gif" />
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </div>
</section>
 -->


  <section class="section">
    <div class="container">

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-two-thirds">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Embodied vision-based real-world systems, such as mobile robots, 
              require a careful balance between energy consumption, compute 
              latency, and safety constraints to optimize operation across 
              dynamic tasks and contexts. As local computation tends to be 
              restricted, offloading the computation, ie, to a remote server, 
              can save local resources while providing access to high-quality 
              predictions from powerful and large models. However, the resulting 
              communication and latency overhead has led to limited usability 
              of cloud models in dynamic, safety-critical, real-time settings. 
              To effectively address this trade-off, we introduce UniLCD, a 
              novel hybrid inference framework for enabling flexible local-cloud 
              collaboration. By efficiently optimizing a flexible routing module 
              via reinforcement learning and a suitable multi-task objective, 
              UniLCD is specifically designed to support the multiple constraints 
              of safety-critical end-to-end mobile systems. We validate the 
              proposed approach using a challenging, crowded navigation task 
              requiring frequent and timely switching between local and cloud 
              operations. UniLCD demonstrates improved overall performance and 
              efficiency, by over 23% compared to state-of-the-art baselines 
              based on various split computing and early exit strategies.
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="container">

      <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Motivation</h2>
          <div class="content has-text-justified">
            <p>
              Our motivation is to solve the research question: How to realize robust 
              vision-based systems that can be flexibly optimized for both <em>safety
              and real-time efficiency</em> while operating in dynamic real-world settings? 
              Processing data through remote cloud servers can deliver high-quality model 
              predictions but introduces latency that is unsuitable for dynamic real-world 
              systems; hence, safety-critical and mobile systems often rely on local 
              processing with model pruning and quantization to meet real-time constraints, 
              though this can degrade accuracy and impact decision-making. Our algorithm proposes 
              a generalized paradigm for situation-specific cloud-local collaboration that 
              balances energy cost and accuracy, optimizing for latency, efficiency, and 
              safety while supporting sustainable system operation.
            </p>
            </p>
            <div class="column" style="text-align: center;">
              <img src="./resources/UniLCD.png" width="80%" />
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Data Description</h2>
          <div class="content has-text-justified">
              The dataset has been collected while navigating through eight 
            predefined routes in the Carla simulation. It includes images 
            captured from the perspective of our ego walker, as well as 
            detailed information about their actions and locations throughout 
            the routes. Below is a brief overview of its contents and structure:
              <ul>
                <li>Images: The images folder contains a series of visuals captured 
                  from the perspective of the ego walker. Each image provides a 
                  first-person view of the walker’s journey, offering a detailed 
                  depiction of the surrounding environment and context.</li>
                <li>Info: This info folder consists of numpy array with 7 columns. 
              The first 2 corresponds to the actions taken by the expert. 
              The 3rd column indicates presence(1)/absence(0) of pedestrian 
              in its visible range. The following  2 represents the current 
              location of the expert and the last two are the closest next 
              path point to the expert.</li>
              </ul>
            </p>
          Directory Organization of UniLCD:
            <ul>
              <p>
              <li>UniLCD
                <ul>
                  <li>Images
                    <ul>
                      <li>1.jpg</li>
                      <li>2.jpg</li>
                      <li>...</li>
                      <li>10.jpg</li>
                      <li>...</li>
                    </ul>
                  </li>
                  <li>Info
                    <ul>
                      <li>1.npy</li>
                      <li>2.npy</li>
                      <li>...</li>
                      <li>10.npy</li>
                      <li>...</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
            </p>
          </div>
        </div>
      </div>
    </div>

    <section class="section">
    <div class="container">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
             We develop a policy for dynamic local and cloud resource allocation to optimize energy efficiency and 
            real-time performance. We achieve this through a formulation of the navigation task, imitation learning 
            for local and cloud navigation policies, and Proximal Policy Optimization (PPO) for a sample-efficient 
            routing policy with a multi-objective reward system. 

            <ol>
              <li><b> Cloud and Local Policies</b>: We use a standard imitation learning with L1 error minimization 
            approach to train navigation policies offline by collecting a diverse dataset from CARLA, featuring complex 
            routes and weather conditions. Both local and cloud policies are developed with shared visual features and 
            goal-conditional modules, where the local policy uses a smaller, optimized version of the pre-trained cloud 
            policy, reducing computational costs.</li>

              <li><b> Routing Policy </b>: We introduce a routing policy that optimally balances local and cloud computing 
              resources using Proximal Policy Optimization (PPO), where the state space includes image embeddings and action 
              history, and the action space is binary for selecting between local or cloud navigation. Our reward function 
              integrates geodesic alignment, speed, energy efficiency, action clipping, and collision penalties to improve 
              optimization and task performance, with specific penalties for sub-optimal actions and collisions to ensure 
              effective and safe navigation.</li>
            </ol>
          </div>
          <div class="content has-text-justified">
          Here is a comprehensive summary of our algorithm.
          </div>
          <div class="column">
            <img src="./resources/algo.png" width="100%" />
          </div>
          <h2 class="title is-4" align="left">UniLCD Algorithm Diagram</h2>
          <div class="content has-text-justified">
            <p>
              We present the architecture diagram of our algorithm, UniLCD, which features a situational routing 
              module that utilizes current embeddings and a history of previous actions. Local actions are 
              predicted by a pre-trained lightweight model for efficient deployment on mobile systems, while 
              a sample-efficient routing module, trained via reinforcement learning, decides whether to execute 
              local actions or transmit the scene embeddings to a more accurate but computationally intensive 
              cloud server model.
            </p>
            <div class="column">
              <img src="./resources/Method.png" />
            </div>

          </div>
        </div>
      </div>
        </div>
      </div>
    
    <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Result</h2>
          <div class="content has-text-justified">
          We present a comparison with previous work, highlighting how our framework addresses system safety, 
          efficiency, and latency holistically, making it well-suited for real-time decision-making in dynamic scenes.
          </div>
          <div class="column">
            <img src="./resources/Comparison.png" width="80%" />
          </div>
          <div class="content has-text-justified">
          We present our algorithm tested on five distinct routes in CARLA's Town 10, with evaluation run comprising 
          30 episodes under varying weather conditions and traffic densities, showing that UniLCD with history achieves
          state-of-the-art performance. We categorize our comparative analysis between individual models (Local and Cloud only), 
          baselines (Deep Learning and RL-based computational offloading research), and our proposed UniLCD variations, which show 
          progressive improvement. <sup>†</sup> denotes methods transmitting raw input data to the cloud, i.e., instead of an embedding.
          </div>
          <div class="column">
            <img src="./resources/Result.png" width="80%" />
          </div>
          <div class="content has-text-justified">
          We map the performance improvement across the entire training process and plot the results, revealing 
            a consistent increase in performance over time.
          </div>
          <div class="column">
            <img src="./resources/Plot.png" width="80%" />
          </div>
        </div>
      </div>
    </div>
  </section>


    
    <!-- Paper video. -->
    <br />
    <br />
    <div id="method_video" class="columns is-centered has-text-centered">
      <div class="column is-half">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video controls>
            <source src="./resources/ECCV_final.mp4" type="video/mp4">
          </video>
<!--           <iframe src="https://www.youtube.com/embed/5tmkDHfgqvU"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

  </section>


  

 <!--  <section class="section">
    <div class="container">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            We develop a novel deep distillation scheme that can address these
            limitations and close the gap between the sensorimotor agent and its
            privileged teacher. We achieve this by

            <ol>
              <li><b>Effective Teacher</b>: We propose to incorporate explicit safety-aware cues
                into the BEV space that facilitate a surprisingly effective teacher agent
                design. We demonstrate our learned agent to match expert- level decisionmaking.</li>

              <li><b>Teachable Student via Alignment</b>: An IPM-based transformer alignment
                module can facilitate direct distillation of most of the teacher’s features and
                better guide the student learning process.</li>

              <li><b>Student-paced Coaching</b>: A coaching mechanism for managing difficult
                samples can scaffold knowledge and lead to improved model optimization
                by better considering the ability of the student.</li>
            </ol>
          </div>
        </div>
      </div>



      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Effective Teacher</h2>
          <div class="content has-text-justified">
            Given the low performance of prior privileged agents, the teacher could benefit from more <b>explicit
            safety-driven cues in the BEV</b>. We propose to add two types of channels of predicted agents’ future and
            entity attention. We first utilize a kinematics bicycle model to predict future trajectories of dynamic
            objects, which enables us to iteratively predict and represent short-term future position, orientation, and
            speed of agent. Then, we encode an explicit attention channel for highlighting potential future infractions.
            Our boosted teacher agent even improves over the rule-based expert.

          </div>
          <div class="column">
            <img src="./resources/bev_figure.png" width="80%" />
          </div>
        </div>
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Teachable student via Alignment</h2>
          <div class="content has-text-justified">
            Due to the difference between inputs and modeling capacities, it can be difficult to align the image-based
            student features and output with the BEV-based privileged teacher. Therefore, we proposed an <b>IPM-based
              transformer alignment module</b> that can facilitate direct distillation of most of the teacher’s features
            and better
            guide the student learning process.
          </div>
          <div class="column">
            <img src="./resources/figure1_crop.png" width="80%" />
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Student-paced Coaching</h2>
          <div class="content has-text-justified">
            To better consider the learning ability of the student, we gradually coach the student with a student-paced
            coaching mechanism. Specifically, we interpolate between teacher features and student features on samples
            that the student performed poorly (i.e. higher loss). This effectively adjusts the learning rate in a
            sample-selective manner, which aims to stabilize training by reducing the difficulty when the student is
            unable to perform the optimal action.
          </div>

          <div class="column">
            <img src="./resources/student_pace.png" width="50%" />
          </div>

        </div>
      </div>


      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4" align="left">Model Architecture of CaT</h2>
          <div class="content has-text-justified">
            <p>
              Our proposed CaT framework
              enables highly effective knowledge transfer between a privileged
              teacher and a sensorimotor (i.e., image-based) student.

              Specifically, we first sample queries using a spatial parameterization of the BEV space and process them
              with a self-attention module. Then, a deformable cross-attention module is applied to populate the
              student’s BEV features.

              The residual blocks following the alignment module can consequently facilitate knowledge transfer via
              direct distillation of most of the teacher’s features.


              Our optimization objective for guiding the distillation process is a weighted sum over both distillation
              and auxiliary tasks, including output distillation loss, feature distillation loss, segmentation loss and
              command prediction loss.
            </p>
            <div class="column">
              <img src="./resources/method.png" />
            </div>

          </div>
        </div>
      </div>


    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Qualitative Examples</h2>
            <video controls>
            <source src="./resources/CaT_Video.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </section>


  <section class="section id=" BibTeX"">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">BibTeX</h2>
          <div class="content has-text-justified">
            <pre><code>@inproceedings{zhang2023coaching,
        title={Coaching a Teachable Student},
        author={Zhang, Jimuyang and Huang, Zanming and Ohn-Bar, Eshed},
        booktitle={CVPR},
        year={2023}
}</code></pre>

          </div>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section id=" BibTeX"">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Acknowledgments</h2>
          <div class="content has-text-centered">
            We thank the Red Hat Collaboratory
            for supporting this research.

          </div>
        </div>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">D-NeRF</span></a>.</p>
      </div>
    </div>
  </footer>

</body>

</html>
